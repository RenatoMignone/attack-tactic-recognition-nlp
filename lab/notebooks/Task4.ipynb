{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996562b2",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919201a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbe41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.12\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.3\n"
     ]
    }
   ],
   "source": [
    "# --- Check Python and pip versions ---\n",
    "!python --version\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "# --- Install required libraries ---\n",
    "!pip install torch\n",
    "!pip install numpy pandas scikit-learn matplotlib seaborn\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f355596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup & Imports ---\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.cuda import is_available\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification, AutoConfig,\n",
    "    get_scheduler, DataCollatorForTokenClassification\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, f1_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "from itertools import chain\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792b97a",
   "metadata": {},
   "source": [
    "### Colab Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dda504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 17 15:55:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# --- Check GPU availability ---\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3645ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 13.6 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "# --- Check RAM availability ---\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982656a",
   "metadata": {},
   "source": [
    "### Paths setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa3083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# --- Mount Google Drive (for Google Colab users) ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff2316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /content/drive/MyDrive/Projects/Laboratory4/\n",
      "Data path: /content/drive/MyDrive/Projects/Laboratory4/data/\n",
      "Results path: /content/drive/MyDrive/Projects/Laboratory4/results/\n"
     ]
    }
   ],
   "source": [
    "# --- Define Paths ---\n",
    "laboratory = 'Laboratory4'\n",
    "\n",
    "base_path = '/content/drive/MyDrive/'\n",
    "project_path = base_path + f'Projects/{laboratory}/'\n",
    "data_path = project_path + 'data/'\n",
    "results_path = project_path + 'results/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(project_path, exist_ok=True)\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "print(f\"Project path: {project_path}\")\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Results path: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e06e3",
   "metadata": {},
   "source": [
    "## Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885efde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GLOBAL CONFIGURATION: Plot Saving (Colab/Google Drive only)\n",
    "# ============================================================================\n",
    "SAVE_PLOTS = 1\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_DIR = results_path + 'Task4'\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "def save_figure_for_report(filename, dpi=300, bbox_inches='tight'):\n",
    "    \"\"\"\n",
    "    Save the current matplotlib figure for use in the report.\n",
    "\n",
    "    Args:\n",
    "        filename: Name of the file (e.g., 'class_distribution.png')\n",
    "        dpi: Resolution (default 300 for high quality)\n",
    "        bbox_inches: Bounding box setting (default 'tight' to remove whitespace)\n",
    "    \"\"\"\n",
    "    if not SAVE_PLOTS:\n",
    "        return  # Skip saving if flag is disabled or filename missing\n",
    "\n",
    "    filepath = os.path.join(BASE_DIR, filename)\n",
    "    plt.savefig(filepath, dpi=dpi, bbox_inches=bbox_inches)\n",
    "    print(f\"Figure saved to: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(full_predictions, full_labels):\n",
    "    \"\"\"Compute token-level classification metrics\"\"\"\n",
    "    flat_predictions = list(chain(*full_predictions))\n",
    "    flat_labels = list(chain(*full_labels))\n",
    "\n",
    "    token_accuracy = accuracy_score(flat_labels, flat_predictions)\n",
    "    token_precision = precision_score(flat_labels, flat_predictions, average='macro', zero_division=0)\n",
    "    token_recall = recall_score(flat_labels, flat_predictions, average='macro', zero_division=0)\n",
    "    token_f1 = f1_score(flat_labels, flat_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    metrics = {\n",
    "        \"token_accuracy\": token_accuracy,\n",
    "        \"token_precision\": token_precision,\n",
    "        \"token_recall\": token_recall,\n",
    "        \"token_f1\": token_f1,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe309ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    \"\"\"Convert predictions and labels to original label format\"\"\"\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfaef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    \"\"\"Align word-level labels to token-level labels\"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aeed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels_unixcoder(samples, tokenizer):\n",
    "    \"\"\"Tokenize and align labels for UniXcoder\"\"\"\n",
    "    split_sentences = [s.split(\" \") for s in samples[\"session\"]]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        split_sentences,\n",
    "        truncation=True,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = samples[\"label_id\"]\n",
    "    aligned_all = []\n",
    "\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized.word_ids(i)\n",
    "\n",
    "        aligned = []\n",
    "        prev_word = None\n",
    "\n",
    "        for wid in word_ids:\n",
    "            if wid is None:\n",
    "                aligned.append(-100)\n",
    "            else:\n",
    "                if wid != prev_word:\n",
    "                    aligned.append(labels[wid])\n",
    "                    prev_word = wid\n",
    "                else:\n",
    "                    aligned.append(-100)\n",
    "        aligned_all.append(aligned)\n",
    "\n",
    "    tokenized[\"labels\"] = aligned_all\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99eae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, lr_scheduler, train_loader, val_loader, device, num_epochs):\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    best_val_loss = np.inf\n",
    "    best_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    # Calculate steps dynamically based on the passed loader\n",
    "    num_training_steps = num_epochs * len(train_loader)\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            # Move batch to device\n",
    "            batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Automatic Mixed Precision\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        predictions_list, labels_list = [], []\n",
    "\n",
    "        for batch in val_loader:\n",
    "            batch = {key: value.to(device, non_blocking=True) for key, value in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                with torch.amp.autocast(device_type='cuda'):  # ← FIXED HERE\n",
    "                    outputs = model(**batch)\n",
    "\n",
    "            val_loss += outputs.loss.item()\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            true_predictions, true_labels = postprocess(predictions, labels)\n",
    "            predictions_list += true_predictions\n",
    "            labels_list += true_labels\n",
    "\n",
    "        # Compute validation metrics\n",
    "        val_metrics = compute_metrics(predictions_list, labels_list)\n",
    "        val_accuracy = val_metrics[\"token_accuracy\"]\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Optional: Print progress\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss <= best_val_loss:\n",
    "            best_epoch = epoch\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_weights = deepcopy(model.state_dict())\n",
    "\n",
    "    # Load the best weights found during this specific training run\n",
    "    model.load_state_dict(best_weights)\n",
    "    return model, best_epoch, best_val_loss, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate model on a dataset\"\"\"\n",
    "    model.eval()\n",
    "    full_predictions, full_labels = [], []\n",
    "    for batch in dataloader:\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "        true_predictions, true_labels = postprocess(predictions, labels)\n",
    "        full_predictions += true_predictions\n",
    "        full_labels += true_labels\n",
    "\n",
    "    test_metrics = compute_metrics(full_predictions, full_labels)\n",
    "    return full_predictions, full_labels, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68532a13",
   "metadata": {},
   "source": [
    "### Re-Train Best Model from Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd359ef6",
   "metadata": {},
   "source": [
    "### Dataset Loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89509fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "train_df = pd.read_json(f\"{data_path}train.json\")\n",
    "test_df = pd.read_json(f\"{data_path}test.json\")\n",
    "\n",
    "print(f\"Training dataset: {train_df.shape[0]} sessions\")\n",
    "print(f\"Test dataset: {test_df.shape[0]} sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c868680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train and validation\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "print(f\"Split training: {train_df.shape[0]} train, {val_df.shape[0]} validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01736845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label mappings\n",
    "unique_labels = list(train_df.label.explode().unique())\n",
    "print(f\"Unique labels: {unique_labels}\")\n",
    "\n",
    "id2label = {it: label for it, label in enumerate(unique_labels)}\n",
    "label2id = {label: it for it, label in enumerate(unique_labels)}\n",
    "\n",
    "print(f\"Label mappings: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Hugging Face datasets\n",
    "full_ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    \"valid\": Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
    "    \"test\": Dataset.from_pandas(test_df.reset_index(drop=True)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to IDs\n",
    "def convert_labels_to_ids(sample):\n",
    "    sample['label_id'] = [label2id[el] for el in sample[\"label\"]]\n",
    "    return sample\n",
    "\n",
    "encoded_dataset = full_ds.map(convert_labels_to_ids)\n",
    "print(f\"Encoded dataset: {encoded_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa05cc",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer and model checkpoint\n",
    "unixcoder_model_checkpoint = \"microsoft/unixcoder-base\"\n",
    "unixcoder_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    unixcoder_model_checkpoint,\n",
    "    add_prefix_space=True,\n",
    "    use_fast=True,\n",
    "    model_max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b09e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets\n",
    "original_columns = encoded_dataset[\"train\"].column_names\n",
    "tokenized_datasets = encoded_dataset.map(\n",
    "    lambda x: tokenize_and_align_labels_unixcoder(x, unixcoder_tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=original_columns,\n",
    ")\n",
    "\n",
    "print(f\"Tokenized dataset: {tokenized_datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4326502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data collator\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=unixcoder_tokenizer,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0435d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"valid\"],\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"DataLoaders created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc588a",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9966fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECTION 3: TRAIN BEST MODEL FROM TASK 3\")\n",
    "print(\"UNIXCODER FULL FINE-TUNE WITH LR=1e-05\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "N_TRAIN_EPOCHS = 40\n",
    "BEST_LR = 1e-5\n",
    "\n",
    "print(f\"\\nTraining parameters:\")\n",
    "print(f\"  - Model: UniXcoder (microsoft/unixcoder-base)\")\n",
    "print(f\"  - Learning Rate: {BEST_LR}\")\n",
    "print(f\"  - Epochs: {N_TRAIN_EPOCHS}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "best_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    unixcoder_model_checkpoint,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler\n",
    "optimizer = optim.AdamW(best_model.parameters(), lr=BEST_LR)\n",
    "\n",
    "num_training_steps = N_TRAIN_EPOCHS * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "best_model, best_epoch, best_val_loss, train_losses, val_losses = training_loop(\n",
    "    best_model, optimizer, lr_scheduler, \n",
    "    train_dataloader, eval_dataloader, device, N_TRAIN_EPOCHS\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Training complete! Best epoch: {best_epoch + 1}, Best val loss: {best_val_loss:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_preds, test_labels, test_metrics = evaluate_model(best_model, test_dataloader, device)\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  - Token Accuracy: {test_metrics['token_accuracy']:.4f}\")\n",
    "print(f\"  - Macro F1-Score: {test_metrics['token_f1']:.4f}\")\n",
    "print(f\"  - Macro Precision: {test_metrics['token_precision']:.4f}\")\n",
    "print(f\"  - Macro Recall: {test_metrics['token_recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47db163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model for later use in inference\n",
    "model_save_path = os.path.join(results_path, \"best_unixcoder_model_task3\")\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "best_model.save_pretrained(model_save_path)\n",
    "unixcoder_tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"\\nBest model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0f099",
   "metadata": {},
   "source": [
    "## Inference Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09daf6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload test data for inference (unlabeled inference sessions)\n",
    "inference_test_df = pd.read_json(f\"{data_path}test.json\")\n",
    "print(f\"Test dataset for inference: {inference_test_df.shape[0]} sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cyberlab.csv for temporal information\n",
    "cyberlab_df = pd.read_csv(f\"{data_path}cyberlab.csv\")\n",
    "print(f\"Cyberlab dataset: {cyberlab_df.shape[0]} records\")\n",
    "print(f\"Columns: {list(cyberlab_df.columns)}\")\n",
    "print(cyberlab_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa01e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_long_words(session, max_length=20):\n",
    "    \"\"\"Truncate words longer than max_length (matching Task 3 preprocessing)\"\"\"\n",
    "    words = session.split()\n",
    "    truncated = []\n",
    "    for word in words:\n",
    "        if len(word) > max_length:\n",
    "            truncated.append(word[:max_length-3] + '...')\n",
    "        else:\n",
    "            truncated.append(word)\n",
    "    return ' '.join(truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ae060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_predictions_to_words(predictions_ids, word_ids, id2label):\n",
    "    \"\"\"\n",
    "    Extract only the prediction for the first token of each word.\n",
    "    Returns list of predicted tactics, one per word.\n",
    "    \"\"\"\n",
    "    aligned_preds_ids = []\n",
    "    seen_words = set()\n",
    "    \n",
    "    for idx, word_id in enumerate(word_ids):\n",
    "        if word_id is None:\n",
    "            continue\n",
    "        if word_id not in seen_words:\n",
    "            aligned_preds_ids.append(predictions_ids[idx])\n",
    "            seen_words.add(word_id)\n",
    "    \n",
    "    aligned_preds = [id2label[pred_id] for pred_id in aligned_preds_ids]\n",
    "    return aligned_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tactics(session_text, model, tokenizer, device, id2label):\n",
    "    \"\"\"\n",
    "    Predict MITRE tactics for a session.\n",
    "    Returns:\n",
    "    - words: list of words\n",
    "    - predictions: list of predicted tactics (one per word)\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    session_clean = truncate_long_words(session_text)\n",
    "    words = session_clean.split()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized = tokenizer(\n",
    "        words,\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    tokenized = {k: v.to(device) for k, v in tokenized.items()}\n",
    "    \n",
    "    # Inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions_ids = logits.argmax(dim=-1).cpu().numpy()[0]\n",
    "    word_ids = tokenized.word_ids(0)\n",
    "    \n",
    "    # Align to words\n",
    "    aligned_preds = align_predictions_to_words(predictions_ids, word_ids, id2label)\n",
    "    \n",
    "    return words, aligned_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a3a98f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "errors = []\n",
    "\n",
    "print(f\"Processing {len(inference_test_df)} sessions for inference...\\n\")\n",
    "\n",
    "for idx, row in inference_test_df.iterrows():\n",
    "    try:\n",
    "        session_text = row['session']\n",
    "        \n",
    "        # Predict tactics\n",
    "        words, predictions = predict_tactics(session_text, best_model, unixcoder_tokenizer, device, id2label)\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'session_id': idx,\n",
    "            'session_text': session_text,\n",
    "            'words': words,\n",
    "            'predictions': predictions,\n",
    "            'fingerprint': tuple(predictions)\n",
    "        })\n",
    "        \n",
    "        if (idx + 1) % 20 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{len(inference_test_df)} sessions...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        errors.append({'session_id': idx, 'error': str(e)})\n",
    "        print(f\"  ERROR on session {idx}: {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n✓ Successfully processed: {len(results_df)}/{len(inference_test_df)} sessions\")\n",
    "if errors:\n",
    "    print(f\"✗ Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97b574",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine cyberlab structure to understand how to match sessions\n",
    "print(\"Cyberlab columns and dtypes:\")\n",
    "print(cyberlab_df.dtypes)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(cyberlab_df.head(3))\n",
    "\n",
    "# Add session index to results for matching with cyberlab\n",
    "results_df['dataset_index'] = range(len(results_df))\n",
    "\n",
    "# Assuming cyberlab.csv rows correspond to test.json rows in order\n",
    "# Add index to cyberlab_df if not present\n",
    "if len(cyberlab_df) >= len(results_df):\n",
    "    cyberlab_df['dataset_index'] = range(len(cyberlab_df))[:len(results_df)]\n",
    "    \n",
    "    # Merge on index\n",
    "    results_df = results_df.merge(\n",
    "        cyberlab_df,\n",
    "        on='dataset_index',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Try to identify date column\n",
    "    date_cols = [col for col in results_df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "    if date_cols:\n",
    "        date_col = date_cols[0]\n",
    "        results_df[date_col] = pd.to_datetime(results_df[date_col], errors='coerce')\n",
    "        date_range = results_df[date_col].dropna()\n",
    "        if len(date_range) > 0:\n",
    "            print(f\"Date range: {date_range.min()} to {date_range.max()}\")\n",
    "        else:\n",
    "            results_df['date'] = pd.to_datetime('2024-01-01')\n",
    "            print(\"Date column exists but couldn't parse dates, using dummy dates\")\n",
    "    else:\n",
    "        results_df['date'] = pd.to_datetime('2024-01-01')\n",
    "        print(\"No date column found in cyberlab.csv, using dummy dates for fingerprint analysis\")\n",
    "else:\n",
    "    results_df['date'] = pd.to_datetime('2024-01-01')\n",
    "    print(f\"Cyberlab has fewer rows ({len(cyberlab_df)}) than results ({len(results_df)}), using dummy dates\")\n",
    "\n",
    "print(f\"Results dataframe shape: {results_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8a7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../data/cyberlab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4423a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>timestamps_statements</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>174262</td>\n",
       "      <td>174262</td>\n",
       "      <td>174191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>174262</td>\n",
       "      <td>174262</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>cat /proc/cpuinfo | grep name | wc -l ; echo -...</td>\n",
       "      <td>2019-12-30 23:56:54.297736+00:00</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  session  \\\n",
       "count                                              174262   \n",
       "unique                                             174262   \n",
       "top     cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
       "freq                                                    1   \n",
       "\n",
       "                   timestamps_statements country_name  \n",
       "count                             174262       174191  \n",
       "unique                            174262          163  \n",
       "top     2019-12-30 23:56:54.297736+00:00        China  \n",
       "freq                                   1        53158  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f7efbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>timestamps_statements</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enable ; system ; shell ; sh ; cat /proc/mount...</td>\n",
       "      <td>2019-09-01 00:00:10.493808+00:00</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enable ; system ; shell ; sh ; cat /proc/mount...</td>\n",
       "      <td>2019-09-01 00:38:41.134935+00:00</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enable ; system ; shell ; sh ; cat /proc/mount...</td>\n",
       "      <td>2019-09-01 00:39:26.263383+00:00</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enable ; system ; shell ; sh ; cat /proc/mount...</td>\n",
       "      <td>2019-09-01 00:40:45.132152+00:00</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable ; system ; shell ; sh ; cat /proc/mount...</td>\n",
       "      <td>2019-09-01 00:54:51.783935+00:00</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174257</th>\n",
       "      <td>cat /proc/cpuinfo | grep name | wc -l ; echo -...</td>\n",
       "      <td>2019-12-30 23:37:10.487881+00:00</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174258</th>\n",
       "      <td>cat /proc/cpuinfo | grep name | wc -l ; echo -...</td>\n",
       "      <td>2019-12-30 23:37:10.923944+00:00</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174259</th>\n",
       "      <td>cat /proc/cpuinfo | grep name | wc -l ; echo -...</td>\n",
       "      <td>2019-12-30 23:41:46.601903+00:00</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174260</th>\n",
       "      <td>cat /proc/cpuinfo | grep name | wc -l ; echo -...</td>\n",
       "      <td>2019-12-30 23:43:34.981985+00:00</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174261</th>\n",
       "      <td>cat /proc/cpuinfo | grep name | wc -l ; echo -...</td>\n",
       "      <td>2019-12-30 23:56:54.297736+00:00</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174262 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  session  \\\n",
       "0       enable ; system ; shell ; sh ; cat /proc/mount...   \n",
       "1       enable ; system ; shell ; sh ; cat /proc/mount...   \n",
       "2       enable ; system ; shell ; sh ; cat /proc/mount...   \n",
       "3       enable ; system ; shell ; sh ; cat /proc/mount...   \n",
       "4       enable ; system ; shell ; sh ; cat /proc/mount...   \n",
       "...                                                   ...   \n",
       "174257  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
       "174258  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
       "174259  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
       "174260  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
       "174261  cat /proc/cpuinfo | grep name | wc -l ; echo -...   \n",
       "\n",
       "                   timestamps_statements country_name  \n",
       "0       2019-09-01 00:00:10.493808+00:00       Israel  \n",
       "1       2019-09-01 00:38:41.134935+00:00       Israel  \n",
       "2       2019-09-01 00:39:26.263383+00:00       Israel  \n",
       "3       2019-09-01 00:40:45.132152+00:00       Israel  \n",
       "4       2019-09-01 00:54:51.783935+00:00       Israel  \n",
       "...                                  ...          ...  \n",
       "174257  2019-12-30 23:37:10.487881+00:00     Thailand  \n",
       "174258  2019-12-30 23:37:10.923944+00:00     Thailand  \n",
       "174259  2019-12-30 23:41:46.601903+00:00  Netherlands  \n",
       "174260  2019-12-30 23:43:34.981985+00:00     Colombia  \n",
       "174261  2019-12-30 23:56:54.297736+00:00        China  \n",
       "\n",
       "[174262 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d9ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
